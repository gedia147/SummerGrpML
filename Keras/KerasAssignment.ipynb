{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasAssignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9wmin_N-BiC"
      },
      "source": [
        "#Introduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQRzMEEa9wWm"
      },
      "source": [
        "Great! Hope that you have a good overview of how to build a basic artificial neural network in Keras. In this assignment, you'll build your own neural network to classify images of the fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is_NgMth-EvE"
      },
      "source": [
        "#The Fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "johq3huC-J-n"
      },
      "source": [
        "The fashion MNIST dataset is a dataset containing 70000 pictures of different clothing items. Each picture is a 28 x 28 pixel image, and belongs to one of 10 differnt classes. The dataset contains 60000 pictures for training and 10000 pictures for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMO1f588_NS5"
      },
      "source": [
        "Each training and test example is assigned to one of the following labels:\n",
        "\n",
        "0:\tT-shirt/top\n",
        "\n",
        "1:\tTrouser\n",
        "\n",
        "2:\tPullover\n",
        "\n",
        "3:\tDress\n",
        "\n",
        "4:\tCoat\n",
        "\n",
        "5:\tSandal\n",
        "\n",
        "6:\tShirt\n",
        "\n",
        "7:\tSneaker\n",
        "\n",
        "8:\tBag\n",
        "\n",
        "9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfEsRSme1xBX"
      },
      "source": [
        "Please go through this link to understand the dataset better:\n",
        "https://github.com/zalandoresearch/fashion-mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5dLDow5_0JO"
      },
      "source": [
        "# Loading the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4QFodeNBRHy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "9bba9788-56be-4784-ecc6-80d93efa51e3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wp-gaN5_4aG"
      },
      "source": [
        "A couple of datasets can easily be loaded into numpy arrays from keras, fashion MNIST being one of them. To store them we simply do the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MU8QW5dADUx"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR9AsufxANXx"
      },
      "source": [
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWzQVjHZAb2-"
      },
      "source": [
        "We see that the training data has 60000 examples with each picture being a 28 x 28 image. So the entire training data is stored as a 60000 x 28 x 28 numpy array. Similary, the test set has 10000 examples\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq-5LZhcBD6f"
      },
      "source": [
        "# Visualizing some of the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sug_8SRQBiSs"
      },
      "source": [
        "To represent the matrix of pixels as an image, we use the matplotlib *imshow()* function. Feel free to change the range of images and see the images of the test set too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlxbpkRkBGk8"
      },
      "source": [
        "n = 10  \n",
        "plt.figure(figsize=(30,6))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(3, n, i + 1)\n",
        "    plt.gray()\n",
        "    plt.imshow(X_train[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuzcIIaeB32a"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGaAncy5C4kj"
      },
      "source": [
        "##Reshaping the matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APYZ5dAsCA8n"
      },
      "source": [
        "Each training and testing example is a 28 x 28 matrix. The entire dataset is a 3 dimensional numpy array. However, to train the dataset as a whole in an ANN, we need a 2 dimensional array. Reshape X_train and X_test so that they are 2 dimensional, with number of rows being intact. The number of columns has to be set by you. (Hint: 28 x 28 image has to be reshaped into one dimension)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZpGIS55CvWK"
      },
      "source": [
        "X_train = #YOUR CODE HERE\n",
        "X_test = #YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FftqQvk2DIWw"
      },
      "source": [
        "##Normalizing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qusXF078EMyj"
      },
      "source": [
        "Previously we used standardization of data, which is performing the mathematical operation $$\\frac{X-\\mu}{\\sigma}$$ on each feature.\n",
        "\n",
        "Now we will be *normalizing data* which is equivalent to performing the mathematical operation $$ \\frac{X - X_{min}}{X_{max} - X_{min}} $$ on each feature.\n",
        "\n",
        "Use scikit learn's MinMaxScaler to normalize the data. Feel free to Google the answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqyYBpq8F5Ii"
      },
      "source": [
        "\"\"\"Normalization of data. Your code goes below\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFB6NGki2RuT"
      },
      "source": [
        "## One hot encoding of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN7GLFhiIaeb"
      },
      "source": [
        "\"\"\"Now convert both y_train and y_test into their one hot encodings. Your code goes below\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZRm3T5FHCTr"
      },
      "source": [
        "#**MAKING THE NEURAL NETWORK MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee2e0c_tHOq2"
      },
      "source": [
        "We now leave the task of making an appropriate neural network model upto you. Use the Sequential model and tweak the number of layers, number of neurons, regularization , dropout rate and other stuff until you get a fairly accurate model. Remember to solve overfitting as much as possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30Hcdx5cHuv0"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "\"\"\"Your neural network model goes below\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axxKzEgIIDth"
      },
      "source": [
        "\"\"\"Use the compile() method to compile your model\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgmkQLPcIMn0"
      },
      "source": [
        "\"\"\"Fit the model using the fit() method and store it in a variable\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9avi-N8IcAM"
      },
      "source": [
        "\"\"\"Plot the training loss, test loss withe each epoch\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_4FbaZYJBH9"
      },
      "source": [
        "\"\"\"Plot the training accuracy, test accuracy with each epoch\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZirCc_Oy3OD6"
      },
      "source": [
        "# NEURAL NETWORK WITH REGULARIZATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHT7h1me3V_P"
      },
      "source": [
        "Now make a neural network model with l2 regularization. Add batch normalization and see if it helps. Please name the Sequential model with something other than \"model\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7-LwgnC3nks"
      },
      "source": [
        "\"\"\"YOUR CODE GOES BELOW\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7bg8RhT37ya"
      },
      "source": [
        "# NEURAL NETWORK WITH DROPOUT "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkXeu04y4B31"
      },
      "source": [
        "Now implement the same neural network as above, but using dropout, and no regularization. Name the model differently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyPeLTke4Q1j"
      },
      "source": [
        "\"\"\"YOUR CODE GOES BELOW\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJBFLyX54WP3"
      },
      "source": [
        "#USING COMBINATION OF DIFFERENT OVERFITTING TECHNIQUES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt8540M44d9t"
      },
      "source": [
        "Now use different combinations of overfitting techniques to get a good test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKQb7PIh4m13"
      },
      "source": [
        "\"\"\"YOUR CODE GOES BELOW\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cogT05WM4uWq"
      },
      "source": [
        "Great! Hope you had fun playing around with the neural network. With this you've come to the end of the artificial neural networks section. Note that there are different types of neural networks, with each performing well in different areas.\n",
        "\n",
        "Happy Learning!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4SsD1vi5Lm1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}